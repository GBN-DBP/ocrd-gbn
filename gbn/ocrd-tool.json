{
  "version": "0.0.1",
  "git_url": "https://github.com/sulzbals/gbn",
  "tools": {
    "ocrd-gbn-sbb-predict": {
      "executable": "ocrd-gbn-sbb-predict",
      "categories": [
        "Layout analysis"
      ],
      "description": "Classifies pixels of input images given a binary (two classes) model and outputs the labels given to each of them as a binary image",
      "steps": [
        "layout/analysis"
      ],
      "input_file_grp": [
        "OCR-D-IMG",
        "OCR-D-BIN"
      ],
      "output_file_grp": [
        "OCR-D-PREDICT"
      ],
      "parameters": {
        "model": {
          "type": "string",
          "description": "Path to Keras model to be used",
          "required": true,
          "cacheable": true
        },
        "shaping": {
          "type": "string",
          "description": "How the images must be processed in order to match the input shape of the model ('resize' for resizing to model shape and 'split' for splitting into patches)",
          "required": true,
          "enum": [
            "resize",
            "split"
          ]
        },
        "operation_level": {
          "type": "string",
          "description": "PAGE XML hierarchy level to operate on",
          "default": "page",
          "enum": [
            "page",
            "region",
            "line"
          ]
        }
      }
    },
    "ocrd-gbn-sbb-binarize": {
      "executable": "ocrd-gbn-sbb-binarize",
      "categories": [
        "Image preprocessing",
        "Layout analysis"
      ],
      "description": "Binarizes the input images by predicting the foreground pixels",
      "steps": [
        "preprocessing/optimization/binarization",
        "layout/analysis"
      ],
      "input_file_grp": [
        "OCR-D-IMG"
      ],
      "output_file_grp": [
        "OCR-D-BIN"
      ],
      "parameters": {
        "model": {
          "type": "string",
          "description": "Path to Keras model to be used",
          "required": true,
          "cacheable": true
        },
        "shaping": {
          "type": "string",
          "description": "How the images must be processed in order to match the input shape of the model ('resize' for resizing to model shape and 'split' for splitting into patches)",
          "default": "split",
          "enum": [
            "resize",
            "split"
          ]
        },
        "caching": {
          "type": "boolean",
          "description": "Enables caching of prediction images from the workspace",
          "default": true
        },
        "operation_level": {
          "type": "string",
          "description": "PAGE XML hierarchy level to operate on",
          "default": "page",
          "enum": [
            "page",
            "region",
            "line"
          ]
        }
      }
    },
    "ocrd-gbn-sbb-crop": {
      "executable": "ocrd-gbn-sbb-crop",
      "categories": [
        "Image preprocessing",
        "Layout analysis"
      ],
      "description": "Crops the input images (must have been binarized) by predicting the actual page surfaces and setting the out-of-page pixels to background (masking them off)",
      "steps": [
        "preprocessing/optimization/cropping",
        "layout/analysis"
      ],
      "input_file_grp": [
        "OCR-D-BIN"
      ],
      "output_file_grp": [
        "OCR-D-CROP"
      ],
      "parameters": {
        "model": {
          "type": "string",
          "description": "Path to Keras model to be used",
          "required": true,
          "cacheable": true
        },
        "shaping": {
          "type": "string",
          "description": "How the images must be processed in order to match the input shape of the model ('resize' for resizing to model shape and 'split' for splitting into patches)",
          "default": "resize",
          "enum": [
            "resize",
            "split"
          ]
        },
        "caching": {
          "type": "boolean",
          "description": "Enables caching of prediction images from the workspace",
          "default": true
        },
        "operation_level": {
          "type": "string",
          "description": "PAGE XML hierarchy level to operate on",
          "default": "page",
          "enum": [
            "page",
            "region",
            "line"
          ]
        }
      }
    },
    "ocrd-gbn-sbb-segment": {
      "executable": "ocrd-gbn-sbb-segment",
      "categories": [
        "Layout analysis"
      ],
      "description": "Segments images by predicting the text regions and lines of the pages (page-level) or by predicting the text lines of the regions (region-level)",
      "steps": [
        "layout/segmentation/region",
        "layout/segmentation/line"
      ],
      "input_file_grp": [
        "OCR-D-DESKEW"
      ],
      "output_file_grp": [
        "OCR-D-SEG"
      ],
      "parameters": {
        "min_particle_size": {
          "type": "number",
          "description": "Minimum ratio of the total segment area for a foreground particle to be considered text",
          "default": 0.00001
        },
        "max_particle_size": {
          "type": "number",
          "description": "Maximum ratio of the total segment area for a foreground particle to be considered text",
          "default": 1.0
        },
        "min_textline_density": {
          "type": "number",
          "description": "Minimum ratio of pixels of a segment predicted as part of text lines for it to be considered a text segment",
          "default": 0.1
        },
        "max_textline_density": {
          "type": "number",
          "description": "Maximum ratio of pixels of a segment predicted as part of text lines for it to be considered a text segment",
          "default": 1.0
        },
        "textregions_model": {
          "type": "string",
          "description": "Path to Keras model to be used for predicting text regions",
          "default": "",
          "cacheable": true
        },
        "textregions_shaping": {
          "type": "string",
          "description": "How the images must be processed in order to match the input shape of the model ('resize' for resizing to model shape and 'split' for splitting into patches)",
          "default": "split",
          "enum": [
            "resize",
            "split"
          ]
        },
        "textlines_model": {
          "type": "string",
          "description": "Path to Keras model to be used for predicting text lines",
          "required": true,
          "cacheable": true
        },
        "textlines_shaping": {
          "type": "string",
          "description": "How the images must be processed in order to match the input shape of the model ('resize' for resizing to model shape and 'split' for splitting into patches)",
          "default": "split",
          "enum": [
            "resize",
            "split"
          ]
        },
        "caching": {
          "type": "boolean",
          "description": "Enables caching of prediction images from the workspace",
          "default": true
        },
        "visualization": {
          "type": "boolean",
          "description": "Enables visualization of segmentation results by saving page images to the image file group. Page-level segmentation visualization consists of the text lines prediction (blue), the binary image foreground (white) and the segmented rectangular text regions (green). Region-level segmentation visualization consists of the original page images with outlines drawn on the segmented text lines (green)",
          "default": false
        },
        "operation_level": {
          "type": "string",
          "description": "PAGE XML hierarchy level to operate on",
          "default": "page",
          "enum": [
            "page",
            "region"
          ]
        }
      }
    }
  }
}
